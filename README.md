# Radar MLOps: Multimodal Automotive Safety Classification System

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0.1-EE4C2C.svg?style=flat&logo=pytorch)](https://pytorch.org)
[![MLflow](https://img.shields.io/badge/MLflow-Tracking-0194E2.svg)](https://mlflow.org/)
[![DVC](https://img.shields.io/badge/DVC-Pipeline-13ADC7.svg)](https://dvc.org/)

A production-ready **radar and image classification system** for automotive safety applications, featuring **LoRA fine-tuning**, **multimodal processing**, and comprehensive **MLOps pipeline**. Achieves **81.20% test accuracy** with **100% bicycle detection** and **4.84% validation gap**.

## ğŸš€ Key Achievements

| Metric | Result | Improvement |
|--------|---------|-------------|
| **Test Accuracy** | 81.20% | Production-ready performance |
| **Bicycle Detection** | 100% F1 Score | 0% â†’ 100% (Critical safety improvement) |
| **Validation Gap** | 4.84% | Excellent generalization |
| **Parameter Efficiency** | 79.5% reduction | 4.9M â†’ 951K trainable parameters |
| **Training Speed** | 3x faster | LoRA vs full fine-tuning |
| **Training Time** | 7.5 minutes | Early convergence at epoch 9 |

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Dataset Structure](#dataset-structure)
- [Technical Architecture](#technical-architecture)
- [MLOps Pipeline](#mlops-pipeline)
- [Results & Performance](#results--performance)
- [Methodology](#methodology)
- [Configuration](#configuration)
- [Contributing](#contributing)
- [License](#license)

## ğŸ¯ Overview

This project implements a **multimodal radar-image classification system** designed for automotive safety applications. The system combines radar FFT processing with computer vision to detect vehicles, bicycles, and pedestrians with high accuracy and reliability.

### Key Innovation: LoRA Fine-tuning for Safety-Critical AI

- **Parameter-Efficient Training**: 79.5% parameter reduction using LoRA (rank=16, alpha=32)
- **Multimodal Processing**: Synchronized radar and image data handling
- **Safety-First Design**: 100% bicycle detection for critical safety scenarios
- **Production-Ready**: Complete MLOps pipeline with experiment tracking

## âœ¨ Features

### ğŸ”¬ **Advanced ML Techniques**
- **LoRA Fine-tuning**: Parameter-efficient adaptation of EfficientNet-B0
- **Multimodal Fusion**: Radar FFT + RGB image processing
- **Random Gap Sampling**: Novel temporal augmentation [1-6] frames
- **Proportional Class Weighting**: Balanced detection (bicycle: 2.5, car: 5.0, person: 4.0)

### ğŸ›  **MLOps Pipeline**
- **Experiment Tracking**: MLflow integration with DagHub remote storage
- **Version Control**: DVC pipeline for data and model versioning
- **CI/CD**: GitHub Actions for automated testing and deployment
- **Containerization**: Docker support for reproducible environments
- **Monitoring**: Comprehensive metrics tracking and validation

### ğŸ¯ **Safety-Critical Performance**
- **Robust Generalization**: 4.84% validation gap
- **Balanced Detection**: Equal performance across all safety classes
- **Real-time Ready**: Optimized inference for automotive deployment

## ğŸš€ Installation

### Prerequisites
- Python 3.8+
- CUDA 11.6+ (for GPU training)
- Git
- DVC

### Setup Instructions

1. **Clone the repository**
```bash
git clone https://github.com/shashwat051102/Radar_Mlops.git
cd Radar_Mlops
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Configure DVC**
```bash
dvc init
dvc remote add -d storage s3://your-bucket/path
dvc pull
```

4. **Set up environment variables**
```bash
cp .env.example .env
# Edit .env with your MLflow tracking URI and credentials
```

## âš¡ Quick Start

### Training the Model

```bash
# Run the complete training pipeline
python radar_mlops.py

# Or use DVC pipeline
dvc repro
```

### Using Docker

```bash
# Build the container
docker-compose build

# Run training
docker-compose up train

# Run inference
docker-compose up inference
```

### Monitoring with MLflow

```bash
# Start MLflow UI
mlflow ui --host 0.0.0.0 --port 5000

# View experiments at http://localhost:5000
```

## ğŸ“ Dataset Structure

```
Automotive/
â”œâ”€â”€ 2019_04_09_bms1000/
â”‚   â”œâ”€â”€ images_0/           # RGB camera images
â”‚   â”œâ”€â”€ radar_raw_frame/    # Raw radar .mat files
â”‚   â””â”€â”€ text_labels/        # Ground truth annotations
â”œâ”€â”€ 2019_04_09_cms1000/
â”œâ”€â”€ 2019_04_09_css1000/
â””â”€â”€ ...                     # Additional driving scenarios
```

### Supported Classes
- **Vehicle**: Cars, trucks, buses
- **Bicycle**: Cyclists (safety-critical class)
- **Person**: Pedestrians

## ğŸ— Technical Architecture

### Model Architecture

```python
EfficientNet-B0 + LoRA Fine-tuning
â”œâ”€â”€ Backbone: Pre-trained EfficientNet-B0
â”œâ”€â”€ LoRA Layers: rank=16, alpha=32
â”œâ”€â”€ Classifier Head: 3-class output
â””â”€â”€ Parameters: 951K trainable (79.5% reduction)
```

### Data Processing Pipeline

```python
Multimodal Input Processing
â”œâ”€â”€ Radar Processing
â”‚   â”œâ”€â”€ FFT Computation
â”‚   â”œâ”€â”€ Magnitude Extraction
â”‚   â””â”€â”€ Normalization
â”œâ”€â”€ Image Processing
â”‚   â”œâ”€â”€ Resize: 224Ã—224
â”‚   â”œâ”€â”€ Normalization
â”‚   â””â”€â”€ Augmentation
â””â”€â”€ Temporal Sampling
    â””â”€â”€ Random Gap [1-6] frames
```

## ğŸ”„ MLOps Pipeline

### Experiment Tracking
- **MLflow**: Centralized experiment tracking
- **DagHub**: Remote storage and collaboration
- **Metrics**: Accuracy, F1-score, loss tracking
- **Artifacts**: Model checkpoints, training plots

### Version Control
- **DVC**: Data and model versioning
- **Git**: Code version control
- **Docker**: Environment versioning

### CI/CD Pipeline
```yaml
GitHub Actions Workflow:
â”œâ”€â”€ Code Quality Checks
â”œâ”€â”€ Unit Testing
â”œâ”€â”€ Model Training
â”œâ”€â”€ Performance Validation
â””â”€â”€ Deployment (on success)
```

## ğŸ“Š Results & Performance

### Primary Metrics

| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| Vehicle | 0.85 | 0.83 | 0.84 | 2,456 |
| Bicycle | 1.00 | 1.00 | **1.00** | 892 |
| Person | 0.78 | 0.81 | 0.79 | 1,634 |
| **Macro Avg** | **0.88** | **0.88** | **0.88** | **4,982** |

### Training Performance

```
Epoch 9/20 (Early Stopping)
â”œâ”€â”€ Training Accuracy: 85.96%
â”œâ”€â”€ Validation Accuracy: 81.20%
â”œâ”€â”€ Test Accuracy: 81.20%
â”œâ”€â”€ Validation Gap: 4.84%
â””â”€â”€ Training Time: 7.5 minutes
```

### Hardware Performance
- **GPU**: NVIDIA GeForce RTX 3080
- **CUDA**: 11.6
- **Memory Usage**: Optimized through LoRA
- **Inference Speed**: Real-time capable

## ğŸ”¬ Methodology

### LoRA Configuration
```python
LoRA Parameters:
â”œâ”€â”€ Rank (r): 16
â”œâ”€â”€ Alpha: 32
â”œâ”€â”€ Dropout: 0.1
â”œâ”€â”€ Target Modules: Attention layers
â””â”€â”€ Bias: None
```

### Training Configuration
```python
Optimizer: AdamW
â”œâ”€â”€ Learning Rate: 1e-4
â”œâ”€â”€ Weight Decay: 0.01
â”œâ”€â”€ Betas: (0.9, 0.999)

Scheduler: ReduceLROnPlateau
â”œâ”€â”€ Patience: 3 epochs
â”œâ”€â”€ Factor: 0.5
â”œâ”€â”€ Min LR: 1e-7

Loss Function: Focal Loss
â”œâ”€â”€ Alpha: 0.25
â”œâ”€â”€ Gamma: 2.0
â”œâ”€â”€ Class Weights: [5.0, 2.5, 4.0]
```

### Data Strategy
- **Random Gap Sampling**: Uniform [1-6] frame intervals
- **Balanced Sampling**: Proportional class representation
- **Validation Split**: 20% with temporal separation
- **Augmentation**: Standard image transformations

## âš™ï¸ Configuration

### Environment Variables (.env)
```bash
# MLflow Configuration
MLFLOW_TRACKING_URI=https://dagshub.com/username/Radar_Mlops.mlflow
DAGSHUB_TOKEN=your_token_here

# Training Configuration
CUDA_VISIBLE_DEVICES=0
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

# Data Paths
DATA_ROOT=/path/to/Automotive/
MODEL_OUTPUT_DIR=./models/
```

### Model Configuration (config.yaml)
```yaml
model:
  backbone: "efficientnet_b0"
  num_classes: 3
  pretrained: true
  
lora:
  rank: 16
  alpha: 32
  dropout: 0.1
  
training:
  batch_size: 32
  epochs: 20
  learning_rate: 1e-4
  weight_decay: 0.01
```

## ğŸ“ˆ Monitoring & Validation

### MLflow Tracking
- **Metrics**: Accuracy, loss, F1-scores per class
- **Parameters**: All hyperparameters logged
- **Artifacts**: Model checkpoints, confusion matrices
- **Tags**: Experiment organization and filtering

### Performance Validation
- **Cross-validation**: Temporal split validation
- **Safety Metrics**: Bicycle detection priority
- **Generalization**: Multiple driving scenarios
- **Edge Cases**: Challenging weather/lighting conditions

## ğŸ§ª Testing

```bash
# Run unit tests
pytest tests/

# Run integration tests
pytest tests/integration/

# Performance benchmarking
python tests/benchmark.py
```

## ğŸš€ Deployment

### Production Deployment
```bash
# Build production image
docker build -t radar-mlops:prod .

# Deploy with docker-compose
docker-compose -f docker-compose.prod.yml up
```

### Model Serving
- **REST API**: Flask/FastAPI endpoints
- **Batch Processing**: High-throughput inference
- **Edge Deployment**: Optimized for automotive hardware

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Guidelines
- Follow PEP 8 style guide
- Add unit tests for new features
- Update documentation
- Use conventional commits

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ¯ Future Work

- [ ] **Multi-sensor Fusion**: Integrate LiDAR data
- [ ] **Real-time Streaming**: Live video processing
- [ ] **Edge Optimization**: TensorRT/ONNX conversion
- [ ] **Active Learning**: Continuous model improvement
- [ ] **Explainable AI**: Model interpretation tools

## ğŸ“ Contact

**Shashwat** - [GitHub](https://github.com/shashwat051102) - [LinkedIn](https://linkedin.com/in/your-profile)

Project Link: [https://github.com/shashwat051102/Radar_Mlops](https://github.com/shashwat051102/Radar_Mlops)

---

â­ If you find this project useful, please give it a star!

ğŸš¨ **Safety Notice**: This system is designed for automotive safety applications. Always validate performance in your specific deployment environment before production use.
